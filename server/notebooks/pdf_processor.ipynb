{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erwan/anaconda3/envs/scienceinfuse/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: DeprecationWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from app.SIWeaviateClient import SIWeaviateClient\n",
    "from app.schemas import Document, ImageChunk, ImageMetadata, TextChunk, TextMetadata\n",
    "from app.processing.image.SIImageDescription import SIImageDescription\n",
    "from app.processing.text.SIITranslator import SITranslator\n",
    "from app.processing.BaseDocumentProcessor import BaseDocumentProcessor\n",
    "import os\n",
    "import fitz\n",
    "import io\n",
    "from PIL import Image\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import re\n",
    "\n",
    "image_descriptor = SIImageDescription()\n",
    "translator = SITranslator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "./data/UniversScience/dossiers-pÃ©dagogiques/marc/cadran_solaire.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erwan/.cache/huggingface/modules/transformers_modules/microsoft/Florence-2-large-ft/c669c6b8bfbd7f0193fcb31f997879045a3612f3/processing_florence2.py:499: DeprecationWarning: invalid escape sequence \\d\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported number of image dimensions: 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==========================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(pdf_path)\n\u001b[0;32m---> 19\u001b[0m pdf \u001b[38;5;241m=\u001b[39m \u001b[43mPDFProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_descriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/clients/ScienceInfuse/server/notebooks/../app/processing/PDFProcessor.py:22\u001b[0m, in \u001b[0;36mPDFProcessor.__init__\u001b[0;34m(self, client, image_descriptor, translator, pdf_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_descriptor \u001b[38;5;241m=\u001b[39m image_descriptor\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslator \u001b[38;5;241m=\u001b[39m translator\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/clients/ScienceInfuse/server/notebooks/../app/processing/BaseDocumentProcessor.py:14\u001b[0m, in \u001b[0;36mBaseDocumentProcessor.__init__\u001b[0;34m(self, client)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# TODO UNCOMMENT\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/clients/ScienceInfuse/server/notebooks/../app/processing/BaseDocumentProcessor.py:23\u001b[0m, in \u001b[0;36mBaseDocumentProcessor.process_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_document\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     document, chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_document(document, chunks)\n",
      "File \u001b[0;32m~/Desktop/clients/ScienceInfuse/server/notebooks/../app/processing/PDFProcessor.py:118\u001b[0m, in \u001b[0;36mPDFProcessor.extract_document\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pdf_images(local_pdf_path)\n\u001b[1;32m    117\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pdf_text_chunks(local_pdf_path)\n\u001b[0;32m--> 118\u001b[0m images_chunks \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription_en\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_descriptor\u001b[38;5;241m.\u001b[39mget_description(image[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])} \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m    119\u001b[0m translated_images_descriptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslator\u001b[38;5;241m.\u001b[39men_to_fr_batch([image[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_en\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images_chunks])\n\u001b[1;32m    120\u001b[0m images_with_descriptions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    121\u001b[0m     {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription_fr\u001b[39m\u001b[38;5;124m\"\u001b[39m: translated_description}\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image, translated_description \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(images_chunks, translated_images_descriptions)\n\u001b[1;32m    123\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/clients/ScienceInfuse/server/notebooks/../app/processing/PDFProcessor.py:118\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pdf_images(local_pdf_path)\n\u001b[1;32m    117\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_pdf_text_chunks(local_pdf_path)\n\u001b[0;32m--> 118\u001b[0m images_chunks \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription_en\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m} \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[1;32m    119\u001b[0m translated_images_descriptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslator\u001b[38;5;241m.\u001b[39men_to_fr_batch([image[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_en\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images_chunks])\n\u001b[1;32m    120\u001b[0m images_with_descriptions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    121\u001b[0m     {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription_fr\u001b[39m\u001b[38;5;124m\"\u001b[39m: translated_description}\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image, translated_description \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(images_chunks, translated_images_descriptions)\n\u001b[1;32m    123\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/clients/ScienceInfuse/server/notebooks/../app/processing/image/SIImageDescription.py:22\u001b[0m, in \u001b[0;36mSIImageDescription.get_description\u001b[0;34m(self, base_64_image)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_description\u001b[39m(\u001b[38;5;28mself\u001b[39m, base_64_image:Image):\n\u001b[1;32m     21\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<MORE_DETAILED_CAPTION>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_64_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device(), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m     23\u001b[0m     generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     24\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     25\u001b[0m         pixel_values\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     27\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m     generated_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/microsoft/Florence-2-large-ft/c669c6b8bfbd7f0193fcb31f997879045a3612f3/processing_florence2.py:250\u001b[0m, in \u001b[0;36mFlorence2Processor.__call__\u001b[0;34m(self, text, images, tokenize_newline_separately, padding, truncation, max_length, return_tensors, do_resize, do_normalize, image_mean, image_std, data_format, input_data_format, resample, do_convert_rgb, do_thumbnail, do_align_long_axis, do_rescale)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_str_or_image(text[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m pixel_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_resize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_resize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_normalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_convert_rgb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_convert_rgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     max_length \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_seq_length  \u001b[38;5;66;03m# max_length has to account for the image tokens\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/scienceinfuse/lib/python3.9/site-packages/transformers/image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/scienceinfuse/lib/python3.9/site-packages/transformers/models/clip/image_processing_clip.py:320\u001b[0m, in \u001b[0;36mCLIPImageProcessor.preprocess\u001b[0;34m(self, images, do_resize, size, resample, do_center_crop, crop_size, do_rescale, rescale_factor, do_normalize, image_mean, image_std, do_convert_rgb, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like you are trying to rescale already rescaled images. If the input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_data_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# We assume that all images have the same channel dimension format.\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     input_data_format \u001b[38;5;241m=\u001b[39m \u001b[43minfer_channel_dimension_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_resize:\n\u001b[1;32m    323\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(image\u001b[38;5;241m=\u001b[39mimage, size\u001b[38;5;241m=\u001b[39msize, resample\u001b[38;5;241m=\u001b[39mresample, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    326\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/scienceinfuse/lib/python3.9/site-packages/transformers/image_utils.py:203\u001b[0m, in \u001b[0;36minfer_channel_dimension_format\u001b[0;34m(image, num_channels)\u001b[0m\n\u001b[1;32m    201\u001b[0m     first_dim, last_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported number of image dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mshape[first_dim] \u001b[38;5;129;01min\u001b[39;00m num_channels:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChannelDimension\u001b[38;5;241m.\u001b[39mFIRST\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported number of image dimensions: 2"
     ]
    }
   ],
   "source": [
    "from app.processing.PDFProcessor import PDFProcessor\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def get_all_pdfs():\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(\"./data\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files\n",
    "\n",
    "\n",
    "with SIWeaviateClient() as client:\n",
    "    pdf_paths = get_all_pdfs()\n",
    "    for pdf_path in pdf_paths:\n",
    "        print(\"==========================================\")\n",
    "        print(pdf_path)\n",
    "        pdf = PDFProcessor(client, image_descriptor, translator, pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = images + texts\n",
    "\n",
    "# Sort the combined list\n",
    "sorted_list = sorted(combined, key=lambda x: (x['page_number'], x['y_coordinate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scienceinfuse)",
   "language": "python",
   "name": "scienceinfuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

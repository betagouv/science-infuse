{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')\n",
    "import sys\n",
    "sys.path.insert(0, '../app')\n",
    "from processing.image.SIImageDescription import SIImageDescription\n",
    "from processing.text.SIITranslator import SITranslator\n",
    "from processing.text.SISurya import SISurya\n",
    "from S3Storage import S3Storage\n",
    "\n",
    "s3 = S3Storage()\n",
    "image_descriptor = SIImageDescription()\n",
    "translator = SITranslator()\n",
    "surya = SISurya()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process single pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.PDFProcessor import PDFProcessor\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "pdf_path = \"./data/exported_document.pdf\"\n",
    "try:\n",
    "    pdf = PDFProcessor(image_descriptor, translator, surya, s3, pdf_path)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(\"ERROR\", e)\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process all pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.PDFProcessor import PDFProcessor\n",
    "import os\n",
    "\n",
    "def get_all_pdfs():\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(\"./data\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "                # pdf_files.append(os.path.abspath(os.path.join(root, file)))\n",
    "    return pdf_files\n",
    "\n",
    "def is_document_already_indexed(pdf_path):\n",
    "    return False\n",
    "    # document = client.collections.get(\"Document\")\n",
    "    # response = document.query.fetch_objects(\n",
    "    #     filters=(\n",
    "    #         Filter.by_property(\"originalPath\").equal(pdf_path)\n",
    "    #     ),\n",
    "    #     limit=1,\n",
    "    #     return_properties=[]\n",
    "    # )\n",
    "    # return len(response.objects) > 0\n",
    "\n",
    "pdf_paths = get_all_pdfs()\n",
    "for pdf_path in pdf_paths:\n",
    "    # print(\"==========================================\")\n",
    "    # print(pdf_path)\n",
    "    if (is_document_already_indexed(pdf_path)):\n",
    "        print(f\"Already in DB, SKIP INDEXING {pdf_path}\")\n",
    "        continue\n",
    "    pdf = PDFProcessor(image_descriptor, translator, pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List\n",
    "import fitz\n",
    "import io\n",
    "import re\n",
    "from PIL import Image, ImageFile\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from pymupdf import Document as PdfDocument\n",
    "from schemas import Document, PdfTextChunk, PdfTextMetadata, BoundingBox, PdfImageChunk, PdfImageMetadata\n",
    "from processing.BaseDocumentProcessor import BaseDocumentProcessor\n",
    "import uuid\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "logger = logging.getLogger()\n",
    "\n",
    "non_space_or_digit_pattern = re.compile(r'[^\\s\\d]')\n",
    "class PDFProcessor(BaseDocumentProcessor):\n",
    "    def __init__(self, image_descriptor: SIImageDescription, translator: SITranslator, surya: SISurya, s3: S3Storage, pdf_path: str, remove_after_upload_to_s3: bool=True):\n",
    "        self.pdf_path = pdf_path\n",
    "        print(\"PDFProcessor pdf_path\", pdf_path, flush=True)\n",
    "        self.image_descriptor = image_descriptor\n",
    "        self.translator = translator\n",
    "        self.surya = surya\n",
    "        self.s3 = s3\n",
    "        self.remove_after_upload_to_s3 = remove_after_upload_to_s3\n",
    "        \n",
    "        return super().__init__()\n",
    "\n",
    "    def save_pdf_to_s3(self, pdf_path):\n",
    "        filename = f\"{self.id}.pdf\"\n",
    "        s3ObjectName = os.path.join('pdf', filename)\n",
    "        # TODO: UNCOMMENT\n",
    "        # self.save_to_s3(self.s3, pdf_path, s3ObjectName, remove=False)\n",
    "        return s3ObjectName\n",
    "    \n",
    "    def unstructured_coordinates_to_bbox(self, coordinates):\n",
    "        if (not coordinates):\n",
    "            return False\n",
    "        x1 = min(coordinates, key=lambda x: x[0])[0]\n",
    "        y1 = min(coordinates, key=lambda x: x[1])[1]\n",
    "        x2 = max(coordinates, key=lambda x: x[0])[0]\n",
    "        y2 = max(coordinates, key=lambda x: x[1])[1]\n",
    "\n",
    "        return BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2)\n",
    "    \n",
    "    def is_single_color(self, image, tolerance=50):\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # Reshape the array to 2D (pixels, color channels)\n",
    "        reshaped = img_array.reshape(-1, img_array.shape[-1])\n",
    "        \n",
    "        # Calculate the difference between each pixel and the first pixel\n",
    "        diff = np.abs(reshaped - reshaped[0])\n",
    "        \n",
    "        # Check if all differences are within the tolerance\n",
    "        return np.all(diff <= tolerance)\n",
    "\n",
    "    def keep_image_based_on_size(self, width, height):\n",
    "        aspect_ratio = width / height\n",
    "        res_megapixel = (width * height) / 1_000_000\n",
    "\n",
    "        if (res_megapixel < 0.03):\n",
    "            return False\n",
    "\n",
    "        # Check if aspect ratio is within an acceptable range\n",
    "        min_aspect_ratio = 0.2\n",
    "        max_aspect_ratio = 6\n",
    "        if aspect_ratio < min_aspect_ratio or aspect_ratio > max_aspect_ratio:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def keep_text(self, text:str):\n",
    "        if (len(text) > 100):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_not_only_space_and_number(self, string):\n",
    "        return bool(non_space_or_digit_pattern.search(string))\n",
    "\n",
    "    def get_image_from_page(self, doc, page):\n",
    "        page = doc[page]\n",
    "        dpi = 72\n",
    "        zoom = dpi / 72  # 72 is the default DPI\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        return img\n",
    "\n",
    "    def get_pdf_text_chunks(self, fitz_document: type[PdfDocument], document: Document):\n",
    "        images = [self.get_image_from_page(fitz_document, pageNumber) for pageNumber in range(len(fitz_document))]\n",
    "        result_imgs, result_preds, result_labels = self.surya.process_images(images)\n",
    "        current_title = \"\"\n",
    "        current_subtitle = \"\"\n",
    "        chunks: List[PdfTextChunk] = []\n",
    "        for page_index in range(len(fitz_document)):\n",
    "            page = fitz_document[page_index]\n",
    "            preds = result_preds[page_index]\n",
    "            labels = result_labels[page_index]\n",
    "            img = result_imgs[page_index]\n",
    "            # Sort bounding boxes by position\n",
    "            sorted_indices = sorted(range(len(preds.bboxes)), key=lambda i: preds.bboxes[i].position)\n",
    "            # Zip and iterate over sorted bounding boxes, labels, and indices\n",
    "            for i in sorted_indices:\n",
    "                box = preds.bboxes[i]\n",
    "                label = labels[i]\n",
    "                \n",
    "                \n",
    "                left, top, right, bottom = box.bbox\n",
    "                # clean text\n",
    "                text = self.surya.restructure_text(page.get_text(\"text\", clip=box.bbox))\n",
    "                if (label in self.surya.TITLES):\n",
    "                    current_title = text\n",
    "                    current_subtitle = \"\"\n",
    "                if (label in self.surya.SUB_TITLES):\n",
    "                    current_subtitle = text\n",
    "\n",
    "                if (self.keep_text(text) is True and label in self.surya.TEXTS):\n",
    "                    chunk = PdfTextChunk(\n",
    "                        document=document,\n",
    "                        text=text,\n",
    "                        title=f\"{current_title}{'>' + current_subtitle if current_subtitle else ''}\",\n",
    "                        metadata=PdfTextMetadata(\n",
    "                            pageNumber=page_index+1,\n",
    "                            bbox=BoundingBox(\n",
    "                                x1=box.bbox[0], \n",
    "                                y1=box.bbox[1], \n",
    "                                x2=box.bbox[2], \n",
    "                                y2=box.bbox[3]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                    chunks.append(chunk)                \n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def save_image(self, image: Image.Image):\n",
    "        output_folder = os.path.join(self.base_download_folder, \"pdf\", \"images\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        file_name = f\"{self.get_random_uuid()}.png\"\n",
    "        image_path = os.path.join(output_folder, file_name)\n",
    "        image.save(image_path, \"PNG\")\n",
    "        image.close()\n",
    "        return image_path, file_name\n",
    "\n",
    "\n",
    "    def get_pdf_images(self, doc: type[PdfDocument]):\n",
    "        temp_images = []\n",
    "        logger.info(\"GET PDF IMAGES logger\")\n",
    "\n",
    "        temp_images = []\n",
    "\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc[page_num]\n",
    "            \n",
    "            for img_index, item in enumerate(doc.get_page_images(page_num)):\n",
    "                try:\n",
    "                    xref = item[0]\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    \n",
    "                    if base_image:\n",
    "                        image_bytes = base_image[\"image\"]\n",
    "                        image_ext = base_image[\"ext\"]\n",
    "                        pil_image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                        if pil_image.mode != \"RGB\":\n",
    "                            pil_image = pil_image.convert(\"RGB\")\n",
    "                        \n",
    "                        x0, y0, x1, y1 = page.get_image_bbox(item[7])\n",
    "                        width = x1 - x0\n",
    "                        height = y1 - y0\n",
    "                        if (self.keep_image_based_on_size(width, height) and not self.is_single_color(pil_image)):\n",
    "                            temp_images.append({\n",
    "                                \"image\": pil_image,\n",
    "                                \"pageNumber\": page_num + 1,\n",
    "                                'bbox': {\"x0\": x0, \"y0\": y0, \"x1\": x1, \"y1\": y1},\n",
    "                                'format': image_ext\n",
    "                            })\n",
    "                        \n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {img_index} on page {page_num}: {str(e)}\")\n",
    "                    continue\n",
    "                                    \n",
    "        return temp_images\n",
    "\n",
    "\n",
    "    def extract_document(self):\n",
    "        print(\"PDFProcessor extract_document self.pdf_path\", self.pdf_path, flush=True)\n",
    "        mediaName =Path(self.pdf_path).stem\n",
    "\n",
    "\n",
    "        pdf_s3ObjectName = self.save_pdf_to_s3(self.pdf_path)\n",
    "\n",
    "        document = Document(\n",
    "            id=self.id,\n",
    "            originalPath=self.pdf_path,\n",
    "            s3ObjectName=pdf_s3ObjectName,\n",
    "            mediaName=mediaName,\n",
    "        )\n",
    "\n",
    "        with fitz.open(self.pdf_path) as fitz_doc:\n",
    "\n",
    "            images = self.get_pdf_images(fitz_doc)\n",
    "            print(\"PDFProcessor extract_document images\", len(images), flush=True)\n",
    "            text_chunks = self.get_pdf_text_chunks(fitz_doc, document)\n",
    "            print(\"PDFProcessor extract_document texts\", len(text_chunks), flush=True)\n",
    "            images_chunks = [{**image, \"description_en\": self.image_descriptor.get_description(image['image'])} for image in images]\n",
    "            # TODO for now deal with error in description ie ;Unsupported number of image dimensions: 2\n",
    "            images_chunks = [chunk for chunk in images_chunks if chunk['description_en'] is not False]\n",
    "            print(\"PDFProcessor extract_document images\", len(images), len(images_chunks), flush=True)\n",
    "            translated_images_descriptions = self.translator.en_to_fr_batch([image['description_en'] for image in images_chunks])\n",
    "            images_with_descriptions = [\n",
    "                {**image, \"description_fr\": translated_description}\n",
    "                for image, translated_description in zip(images_chunks, translated_images_descriptions)\n",
    "            ]\n",
    "            \n",
    "            chunks = []\n",
    "            # create chunks for every images, and save them to s3\n",
    "            for img in images_with_descriptions:\n",
    "                image_path, file_name = self.save_image(img.get('image'))\n",
    "                image_s3ObjectName = f\"{pdf_s3ObjectName}/images/{file_name}\"\n",
    "                self.save_to_s3(self.s3, image_path, image_s3ObjectName)\n",
    "                img.get('image').close()\n",
    "\n",
    "                chunk = PdfImageChunk(\n",
    "                    text=img.get('description_fr'),\n",
    "                    title=\"\",\n",
    "                    document=document,\n",
    "                    metadata=PdfImageMetadata(\n",
    "                        s3ObjectName=image_s3ObjectName,\n",
    "                        pageNumber=img.get('pageNumber'),\n",
    "                        bbox=BoundingBox(\n",
    "                            x1=img.get('bbox',{}).get('x1', -1), \n",
    "                            y1=img.get('bbox',{}).get('x1', -1), \n",
    "                            x2=img.get('bbox',{}).get('x1', -1), \n",
    "                            y2=img.get('bbox',{}).get('x1', -1)\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                chunks.append(chunk)\n",
    "            for text_chunk in text_chunks:\n",
    "                chunks.append(text_chunk)\n",
    "    \n",
    "            if (self.remove_after_upload_to_s3 is True):\n",
    "                os.remove(self.pdf_path)\n",
    "            return document, chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../../.env')\n",
    "import sys\n",
    "sys.path.insert(0, '../app')\n",
    "\n",
    "import io\n",
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "pdf_path = \"/home/erwan/Downloads/RevueDecouverte/decouverte_410.pdf\"\n",
    "# pdf_path = \"/home/erwan/Downloads/test_index.pdf\"\n",
    "\n",
    "pdf = PDFProcessor(image_descriptor, translator, surya, s3, pdf_path)\n",
    "document, chunks = pdf.extract_document()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from pymupdf import Document as PdfDocument\n",
    "\n",
    "pdf_path = \"/home/erwan/Downloads/RevueDecouverte/decouverte_409.pdf\"\n",
    "fitz_doc = fitz.open(pdf_path)\n",
    "\n",
    "def get_pdf_images(doc: type[PdfDocument]):\n",
    "    temp_images = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        for img_index, item in enumerate(doc.get_page_images(page_num)):\n",
    "            try:\n",
    "                xref = item[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                \n",
    "                if base_image:\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image_ext = base_image[\"ext\"]\n",
    "                    pil_image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "                    print(pil_image.mode)\n",
    "                    if pil_image.mode in [\"CMYK\", \"P\", \"L\", \"LA\", \"PA\"]:\n",
    "                        pil_image = pil_image.convert(\"RGB\", colors=256)\n",
    "                    \n",
    "                    # Get transformation matrix and bounding box\n",
    "\n",
    "                    # Fix issues where extracted images are mirrored.\n",
    "                    # Check for mirroring and rotation using the matrix\n",
    "                    box_and_transform = page.get_image_bbox(item[7], transform=True)\n",
    "                    print(\"len(box_and_transform)\", len(box_and_transform))\n",
    "                    if (len(box_and_transform) == 2):\n",
    "                        print(\"box_and_transform\", len(box_and_transform),box_and_transform, item[7])\n",
    "                        # bbox, transform = box_and_transform\n",
    "                        # # See : https://github.com/pymupdf/PyMuPDF/issues/385\n",
    "                        # if min(transform.a, transform.d) < 0:\n",
    "                        #     if transform.a < 0:  # Horizontal flip\n",
    "                        #         pil_image = pil_image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                        #     if transform.d < 0:  # Vertical flip\n",
    "                        #         pil_image = pil_image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "                        # # Apply rotation based on matrix\n",
    "                        # if transform.a != transform.d:\n",
    "                        #     if transform.a < 0 and transform.d < 0:\n",
    "                        #         pil_image = pil_image.rotate(180)\n",
    "                        #     elif transform.a == 0 and transform.d > 0:\n",
    "                        #         pil_image = pil_image.rotate(90)\n",
    "                        #     elif transform.a > 0 and transform.d == 0:\n",
    "                        #         pil_image = pil_image.rotate(-90)\n",
    "                    else:\n",
    "                        bbox = page.get_image_bbox(item[7])\n",
    "                    # x0, y0, x1, y1 = bbox\n",
    "                    # width = x1 - x0\n",
    "                    # height = y1 - y0\n",
    "                    \n",
    "                    # temp_images.append({\n",
    "                    #     \"image\": pil_image,\n",
    "                    #     \"pageNumber\": page_num + 1,\n",
    "                    #     'bbox': {\"x0\": x0, \"y0\": y0, \"x1\": x1, \"y1\": y1},\n",
    "                    #     'format': image_ext\n",
    "                    # })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_index} on page {page_num}: {str(e)}\")\n",
    "                return temp_images\n",
    "                continue\n",
    "                                \n",
    "    return temp_images\n",
    "\n",
    "\n",
    "\n",
    "images = get_pdf_images(fitz_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(images[:10]):\n",
    "    print(i)\n",
    "    display(image[\"image\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienceinfuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

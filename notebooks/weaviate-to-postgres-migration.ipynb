{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import dotenv\n",
    "from weaviate.classes.query import Filter, QueryReference\n",
    "\n",
    "dotenv.load_dotenv('../.env')\n",
    "\n",
    "# Add parent directory to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'server')))\n",
    "\n",
    "from app.SIWeaviateClient import SIWeaviateClient\n",
    "\n",
    "import weaviate\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PostgreSQL connection\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"scienceinfuse\", \n",
    "    user=\"postgres\", \n",
    "    password=f\"{os.environ['POSTGRES_PASSWORD']}\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "register_vector(cur)\n",
    "\n",
    "# Helper function to insert document\n",
    "def insert_document(document_uuid, doc):\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO \"Document\" (id, \"s3ObjectName\", \"originalPath\", \"publicPath\", \"mediaName\")\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        RETURNING id\n",
    "    \"\"\", (\n",
    "        document_uuid, doc['s3_object_name'], doc['original_path'], doc.get('public_path'), doc['media_name']\n",
    "    ))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "\n",
    "# Helper function to insert document chunk\n",
    "def insert_chunk(chunk_uuid, chunk, text_embedding, document_uuid):\n",
    "    for field in ['text', 'title', 'media_type']:\n",
    "        if field in chunk and '\\x00' in chunk[field]:\n",
    "            chunk[field] = chunk[field].replace('\\x00', '')\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO \"DocumentChunk\" (id, \"text\", \"textEmbedding\", \"title\", \"mediaType\", \"documentId\")\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        RETURNING id\n",
    "    \"\"\", (\n",
    "        chunk_uuid, chunk['text'], text_embedding, chunk['title'], chunk['media_type'], document_uuid\n",
    "    ))\n",
    "    chunk_id = cur.fetchone()[0]\n",
    "    meta_uuid = str(uuid.uuid4())\n",
    "\n",
    "    # Insert metadata\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO \"DocumentChunkMeta\" (id, \"documentChunkId\", \"s3ObjectName\", \"pageNumber\", \"bbox\", \"type\", \"start\", \"end\", \"question\", \"answer\", \"url\", \"description\", \"title\")\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        meta_uuid, chunk_id, \n",
    "        chunk['meta_s3_object_name'], \n",
    "        chunk.get('meta_page_number'),\n",
    "        json.dumps(chunk.get('meta_bbox')), \n",
    "        chunk.get('meta_type'),\n",
    "        chunk.get('meta_start'), \n",
    "        chunk.get('meta_end'),\n",
    "        chunk.get('meta_question'), \n",
    "        chunk.get('meta_answer'), \n",
    "        chunk.get('meta_url'),\n",
    "        chunk.get('meta_description'),\n",
    "        chunk.get('meta_title'),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Migrating Documents: 11404it [00:02, 3848.40it/s]\n",
      "Migrating DocumentChunk: 1080it [00:03, 310.02it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "count = {}\n",
    "with SIWeaviateClient() as client:\n",
    "    # Migrate Documents\n",
    "    document = client.collections.get(\"Document\")\n",
    "    documentChunk = client.collections.get(\"DocumentChunk\")\n",
    "\n",
    "    # INSERT DOCUMENT\n",
    "    doc_count = 0\n",
    "    for doc in tqdm(document.iterator(), desc=\"Migrating Documents\"):\n",
    "        document_uuid = str(doc.uuid)\n",
    "        insert_document(document_uuid, doc.properties)\n",
    "        doc_count += 1\n",
    "        if doc_count % 1000 == 0:\n",
    "            conn.commit()\n",
    "\n",
    "    chunk_count = 0\n",
    "    for chunk in tqdm(documentChunk.iterator(include_vector=True,return_references=[QueryReference(\n",
    "            link_on=\"belongsToDocument\",\n",
    "            include_vector=True, \n",
    "        )]), desc=\"Migrating DocumentChunk\"):\n",
    "        chunk_uuid = str(chunk.uuid)\n",
    "        chunk_properties = chunk.properties\n",
    "        media_type = chunk_properties.get('media_type')\n",
    "        chunk_vector = chunk.vector.get(\"default\")\n",
    "        if (\"belongsToDocument\" in chunk.references):\n",
    "            parent_document_uuid = str(chunk.references[\"belongsToDocument\"].objects[0].uuid)\n",
    "            insert_chunk(chunk_uuid, chunk_properties, chunk_vector, parent_document_uuid)        \n",
    "        else:\n",
    "            print('-----------')\n",
    "            print(chunk_properties)\n",
    "        chunk_count += 1\n",
    "        if chunk_count % 1000 == 0:\n",
    "            conn.commit()\n",
    "\n",
    "    conn.commit()  # Final commit for any remaining documents and chunks\n",
    "    print(\"Migration completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scienceinfuse",
   "language": "python",
   "name": "scienceinfuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/erwan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "/home/erwan/anaconda3/envs/scienceinfuse/lib/python3.9/site-packages/google/api_core/exceptions.py:37: ImportWarning: Please install grpcio-status to obtain helpful grpc error messages.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package omw-1.4 to /home/erwan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from app.processing.stt.SIWhisperModel import SIWhisperModel\n",
    "from app.SIWeaviateClient import SIWeaviateClient\n",
    "from app.processing.YoutubeProcessor import YoutubeProcessor\n",
    "\n",
    "whisper = SIWhisperModel('medium', 'whisper-medium')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO CODEC aac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper-medium: 100%|██████████| 167.346/167.346 [00:10<00:00, 16.38s/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_taken 10.6313955783844\n"
     ]
    }
   ],
   "source": [
    "with SIWeaviateClient() as client:\n",
    "    YoutubeProcessor(client=client, whisper=whisper, youtube_url=\"https://www.youtube.com/watch?v=QMJmmJqDL1w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from weaviate.classes.query import Filter, GeoCoordinate, MetadataQuery, QueryReference, GroupBy\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "from weaviate.classes.query import QueryReference\n",
    "\n",
    "def hybrid_search_chunks(query, limit=5):\n",
    "    document_chunks = client.collections.get(\"DocumentChunk\")\n",
    "    \n",
    "    response = document_chunks.query.hybrid(\n",
    "        query=query,\n",
    "        alpha=0.5,  # Adjust this value to balance between vector and keyword search\n",
    "        limit=limit,\n",
    "        return_metadata=[\"score\"],\n",
    "        return_references=QueryReference(\n",
    "            link_on=\"belongsToDocument\",\n",
    "            return_properties=[\"document_id\", \"media_name\"]\n",
    "        ),\n",
    "        group_by=GroupBy(\n",
    "            prop=\"belongsToDocument\",\n",
    "            number_of_groups=limit,\n",
    "            objects_per_group=3  # Adjust this as needed\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "hybrid_search_chunks(\"axolot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import (\n",
    "    MetadataQuery,\n",
    "    HybridFusion,\n",
    "    GroupBy,\n",
    "    Filter,\n",
    ")\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "def hybrid_search_and_group(search_term, limit=10):\n",
    "    document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "    \n",
    "    response = document_chunk.query.hybrid(\n",
    "        query=search_term,\n",
    "        alpha=0.5,  # Adjust this value to balance between vector and keyword search\n",
    "        fusion_type=HybridFusion.RELATIVE_SCORE,\n",
    "        query_properties=[\n",
    "            \"text\",\n",
    "        ],\n",
    "        limit=limit,\n",
    "        return_metadata=MetadataQuery(\n",
    "            distance=True,\n",
    "            score=True,\n",
    "        ),\n",
    "        group_by=GroupBy(\n",
    "            prop=\"belongsToDocument\",\n",
    "            number_of_groups=10,  # Adjust this value based on how many document groups you want\n",
    "            objects_per_group=5,  # Adjust this value based on how many chunks per document you want\n",
    "        ),\n",
    "        # filters=Filter.by_property(\"belongsToDocument\").not_equal(None),\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "# Usage\n",
    "search_results = hybrid_search_and_group(\"your search term here\")\n",
    "print(\"search_results\", search_results)\n",
    "# Process and print results\n",
    "for group_name, group in search_results.groups.items():\n",
    "    print(f\"Document: {group_name}\")\n",
    "    print(f\"Number of chunks: {group.number_of_objects}\")\n",
    "    for obj in group.objects:\n",
    "        print(f\"  Chunk: {obj.properties['text'][:50]}...\")  # Print first 50 characters of each chunk\n",
    "        print(f\"  Score: {obj.metadata.score}\")\n",
    "        print(f\"  Distance: {obj.metadata.distance}\")\n",
    "        print(\"---\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local()\n",
    "\n",
    "\n",
    "# document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "# document = client.collections.get(\"Document\")\n",
    "# response = document_chunk.query.hybrid(\n",
    "#     query=\"sniper\",\n",
    "#     # alpha=0.5,\n",
    "#     query_properties=[\"text\"],\n",
    "#     return_references=[QueryReference(link_on=\"belongsToDocument\", return_properties=[\"document_id\", \"media_name\"])],\n",
    "#     # limit=10,\n",
    "#     group_by=GroupBy(\n",
    "#         prop=\"belongsToDocument\",\n",
    "#         number_of_groups=10,\n",
    "#         objects_per_group=5,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# print(\"\\n\\n==============\\n\\n\")\n",
    "# print(response)\n",
    "# print(\"\\n\\n==============\\n\\n\")\n",
    "# for group_name, group in response.groups.items():\n",
    "#     print(f\"Document: {group_name}\")\n",
    "#     print(f\"Number of chunks: {group.number_of_objects}\")\n",
    "#     for obj in group.objects:\n",
    "#         print(f\"  Chunk: {obj.properties['text'][:50]}...\")  # Print first 50 characters of each chunk\n",
    "#         print(\"---\")\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "\n",
    "group_by = GroupBy(\n",
    "    prop=\"belongsToDocument.document_id\",  # group by this cross-referenced property\n",
    "    objects_per_group=3,  # maximum objects per group\n",
    "    number_of_groups=2,  # maximum number of groups\n",
    ")\n",
    "\n",
    "# Perform the hybrid query\n",
    "document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "response = document_chunk.query.hybrid(\n",
    "    alpha=0.75,\n",
    "    query=\"your_search_query\",  # replace with your actual search query\n",
    "    group_by=group_by,\n",
    "    return_references=[QueryReference(link_on=\"belongsToDocument.document_id\")]  # include the cross-referenced property\n",
    ")\n",
    "\n",
    "client.close()\n",
    "print(response)\n",
    "# Print the grouped results\n",
    "for grp_name, grp_content in response.groups.items():\n",
    "    print(grp_name, grp_content.objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_local()\n",
    "\n",
    "# Define the grouping parameters\n",
    "group_by = GroupBy(\n",
    "    prop=\"belongsToDocument.media_name\",  # group by this cross-referenced property\n",
    "    number_of_groups=10,  # maximum number of groups\n",
    "    objects_per_group=5,  # maximum objects per group\n",
    ")\n",
    "\n",
    "# Perform the hybrid query\n",
    "document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "document = client.collections.get(\"Document\")\n",
    "response = document_chunk.query.hybrid(\n",
    "    query=\"sniper\",  # replace with your actual search query\n",
    "    query_properties=[\"text\"],  # specify the property to search\n",
    "    return_references=[QueryReference(link_on=\"belongsToDocument\", return_properties=[\"document_id\", \"media_name\"])],  # include the cross-referenced properties\n",
    "    group_by=group_by,\n",
    ")\n",
    "\n",
    "client.close()\n",
    "# Print the grouped results\n",
    "print(response)\n",
    "for grp_name, grp_content in response.groups.items():\n",
    "    print(grp_name, grp_content.objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ile de Paques : la théorie de l’effondrement précolonial à nouveau démentie | Actu de science\n",
      "    -->  1.0 | Une croyance encore bien ancrée dans les esprits laisse penser que jadis, les habitants de l'île de Pâques, de son nom autochtone Rapanoui, auraient surexploité leur environnement naturel, provoquant ainsi eux-mêmes leur disparition. Mais cette hypothèse a été maintes fois démentie et une nouvelle étude enfonce le clou.\n",
      "    -->  0.7116864323616028 | En effet, l'île n'a jamais accueilli assez d'humains pour que cela ait entraîné leur Lorsque Rapa Nui est accosté par les colons européens, en 1722, il découvre d'imposantes statues de pierres érigées par milliers. Pourtant, il n'y a que 3 000 habitants sur place. Une question se pose alors, comment un si petit nombre d'individus a-t-il pu édifier de si nombreuses et si monumentales constructions ? Selon une idée popularisée par le géographe américain Jared Diamond il y a une vingtaine d'années, Rapa Nui était habité par de nombreux autochtones à même de dresser ces gigantesques statues. Mais en pliant les ressources naturelles dès avant l'arrivée des colons, ils auraient causé leur propre effondrement démographique. Or, les données scientifiques actuelles racontent une toute autre histoire. Une étude publiée en 2013 estimait que 4 à 21 km² de Rapa Nui étaient couverts de jardins de pierre utilisés pour cultiver des aliments comme des patates douces. L'île serait alors capable de nourrir jusqu'à 16 000 habitants. Mais ce chiffre est mis à mal par la dernière étude en date, publié le 21 juin dans Science Advances. En alliant imagerie satellite infrarouge à onde courte et intelligence artificielle, elle a pu identifier minutieusement les jardins de pierre en les distinguant des autres paysages rocheux de l'île, chose que l'étude de 2013 ne faisait pas de manière précise. Conclusion, les estimations de la quantité de jardins de pierre, ici en bleu, varient considérablement. À gauche, les estimations de l'étude de 2013, et à droite, celles de la récente étude. D'après cette dernière, les jardins de pierre ne couvraient en fait que 0,76 km² de l'île. Or, qui dit moins de jardins de pierre, dit moins d'aliments terrestres et donc moins d'habitants. L'île n'aurait en fait été capable d'accueillir que près de 4 000 habitants et non pas des dizaines de milliers. Pour l'archéologue Karl Lipo, qui a mené ses travaux, le récit d'un effondrement pré-européen n'a tout simplement aucun fondement. ni dans les archives archéologiques, ni dans la nature géologique du paysage, ni dans les ressources disponibles, ni dans les récits historiques. Si effondrement démographique il y a eu, c'est bien avec l'arrivée des colons européens qu'il s'est produit. Ce qu'on peut retenir de l'histoire des Rapanouis, en revanche, c'est l'ingéniosité avec laquelle ils ont exploité les maigres ressources disponibles sur leur île.\n",
      "Un 3e pouce pour tester la plasticité cérebrale | Actu de science\n",
      "    -->  0.07216962426900864 | Que pourrait-on faire si l'on disposait d'un doigt supplémentaire ? Quels changements cela impliquerait-il dans le cerveau ? Et tout le monde serait-il capable de se l'approprier ? C'est à ces questions que Dani Claude, designer et membre du laboratoire plasticité cérébrale à l'université de Cambridge, tente de répondre avec un dispositif qu'elle a créé est appelé le troisième pouce. Ça c'est mon troisième pouce, un pouce flexible avec deux moteurs dont un sur le poignet. Mon pied gauche déclenche ce mouvement vers le haut et vers le bas et c'est proportionnel donc je peux aller vite ou lentement. Et avec mon orteil droit, je peux ramener le doigt. Fabriqué par une imprimante 3D, ce troisième pouce est donc un dispositif sans fil contrôlé par deux capteurs situés sous les orteils est relié aux bras par une connexion Bluetooth. Dans une première étude, 36 participants se sont prêtés au jeu avec succès. Certains l'ont même testé les yeux bandés, sans difficulté pour le faire fonctionner. Ils ont ensuite été encouragés à l'utiliser à la maison.\n",
      "    -->  0.011302422732114792 | Les IRM du cerveau des participants, passés avant et après l'expérience, ont montré que l'exercice a entraîné des changements légers mais significatif de la représentation de la main dans le cortex sensorimoteur, alors même que celle-ci reste intacte chez des personnes nées avec six doigts fonctionnels ou ayant perdu l'usage de leurs mains ou leurs membres. Dans une seconde étude conduite à l'été 2023, l'équipe a saisi l'opportunité d'une exposition de cinq jours à la Royal Society à Londres pour donner à expérimenter le dispositif à un public large et varié et tester son appropriation. Sur les quelques 600 participants, âgés de 3 à 96 ans, qui se sont prêtés à l'exercice, 98% ont réussi à utiliser le troisième pouce et à manipuler des objets dès la première minute, avec des performances cependant moindres pour les enfants de moins de 11 ans et les personnes âgées. L'ambition des chercheurs est justement dans une prochaine étape de travailler avec des enfants ainsi qu'avec des personnes présentant des déficiences ou des handicaps moteurs. Quant à l'impact de ce dispositif sur le cerveau, seule une étude sur le long terme pourrait approfondir le sujet.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from collections import defaultdict\n",
    "from app.schemas import ChunkWithScore, DocumentSearchResult\n",
    "from weaviate.classes.query import Filter, GeoCoordinate, MetadataQuery, QueryReference, GroupBy\n",
    "\n",
    "\n",
    "query = \"l'île de Pâques\"\n",
    "client = weaviate.connect_to_local()\n",
    "# print(\"SEARCH_MULTI_DOCUMENTS 0 \", query)\n",
    "document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "response = document_chunk.query.hybrid(\n",
    "    query=query,\n",
    "    return_metadata=wvc.query.MetadataQuery(score=True),\n",
    "    query_properties=[\"text\"],\n",
    "    return_references=[QueryReference(link_on=\"belongsToDocument\", return_properties=[\"document_id\", \"local_path\", \"original_public_path\", \"media_name\", \"max_score\", \"min_score\"])]\n",
    ")\n",
    "# print(\"SEARCH_MULTI_DOCUMENTS 1 \", response)\n",
    "client.close()\n",
    "\n",
    "# Assume response is the result from the above query\n",
    "grouped_results = defaultdict(list)\n",
    "for chunk in response.objects:\n",
    "    doc_ref = chunk.references['belongsToDocument'].objects[0].properties\n",
    "    grouped_results[doc_ref['document_id']].append(chunk)\n",
    "\n",
    "# Now `grouped_results` contains your data grouped by 'document_id'\n",
    "# for document_id, chunks in grouped_results.items():\n",
    "#     print(f\"Media id: {document_id}, || Chunks: {chunks}\")\n",
    "\n",
    "documentsSearchResponse = []\n",
    "\n",
    "for document_id, group in grouped_results.items():  # View by group\n",
    "    # max_score = min(chunk for chunk in group)#group.max_score\n",
    "    # min_score = min(chunk for chunk in group)#group.min_score\n",
    "    currentDocumentChunksWithDistance = []\n",
    "    for _documentChunk in group:\n",
    "        score = _documentChunk.metadata.score\n",
    "        cuurrentChunkWithScore = ChunkWithScore.model_validate({**_documentChunk.properties, \"score\": score})\n",
    "        currentDocumentChunksWithDistance.append(cuurrentChunkWithScore)\n",
    "    \n",
    "    documentProperties = _documentChunk.references['belongsToDocument'].objects[0].properties\n",
    "    \n",
    "    documentSearchResult = DocumentSearchResult(\n",
    "        document_id=documentProperties['document_id'],\n",
    "        local_path=documentProperties['local_path'],\n",
    "        original_public_path=documentProperties['original_public_path'],\n",
    "        media_name=documentProperties['media_name'],\n",
    "        min_score=min(chunk.score for chunk in currentDocumentChunksWithDistance),\n",
    "        max_score=max(chunk.score for chunk in currentDocumentChunksWithDistance),\n",
    "        chunks=currentDocumentChunksWithDistance\n",
    "    )\n",
    "    documentsSearchResponse.append(documentSearchResult)\n",
    "for doc in documentsSearchResponse:\n",
    "    print(doc.media_name)\n",
    "    for chunk in doc.chunks:\n",
    "        print(f\"    -->  {chunk.score} | {chunk.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.objects[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import (\n",
    "    MetadataQuery,\n",
    "    HybridFusion,\n",
    "    GroupBy,\n",
    "    Filter,\n",
    ")\n",
    "from weaviate import Client\n",
    "from weaviate.classes.config import Property, DataType, ReferenceProperty\n",
    "\n",
    "# Initialize the client\n",
    "client = Client(\"http://localhost:8080\")\n",
    "client.query \\\n",
    "   .get(\"DocumentChunk\", [\"text belongsToDocument {... on Document {document_id local_path} }\"]) \\\n",
    "   .with_near_text({\"concepts\": [\"biology\"]}) \\\n",
    "    .with_group_by([\"belongsToDocument\"],groups=2,objects_per_group=2) \\\n",
    "   .with_limit(3) \\\n",
    "   .with_additional(['certainty']) \\\n",
    "   .do()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scienceinfuse)",
   "language": "python",
   "name": "scienceinfuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

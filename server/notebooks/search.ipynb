{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Document Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from collections import defaultdict\n",
    "from app.schemas import ChunkWithScore, DocumentSearchResult\n",
    "from weaviate.classes.query import Filter, GeoCoordinate, MetadataQuery, QueryReference, GroupBy\n",
    "\n",
    "\n",
    "query = \"l'île de Pâques\"\n",
    "client = weaviate.connect_to_local()\n",
    "# print(\"SEARCH_MULTI_DOCUMENTS 0 \", query)\n",
    "document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "response = document_chunk.query.hybrid(\n",
    "    query=query,\n",
    "    return_metadata=wvc.query.MetadataQuery(score=True),\n",
    "    query_properties=[\"text\"],\n",
    "    return_references=[QueryReference(link_on=\"belongsToDocument\", return_properties=[\"document_id\", \"local_path\", \"original_public_path\", \"media_name\", \"max_score\", \"min_score\"])]\n",
    ")\n",
    "# print(\"SEARCH_MULTI_DOCUMENTS 1 \", response)\n",
    "client.close()\n",
    "\n",
    "# Assume response is the result from the above query\n",
    "grouped_results = defaultdict(list)\n",
    "for chunk in response.objects:\n",
    "    doc_ref = chunk.references['belongsToDocument'].objects[0].properties\n",
    "    grouped_results[doc_ref['document_id']].append(chunk)\n",
    "\n",
    "# Now `grouped_results` contains your data grouped by 'document_id'\n",
    "# for document_id, chunks in grouped_results.items():\n",
    "#     print(f\"Media id: {document_id}, || Chunks: {chunks}\")\n",
    "\n",
    "documentsSearchResponse = []\n",
    "\n",
    "for document_id, group in grouped_results.items():  # View by group\n",
    "    # max_score = min(chunk for chunk in group)#group.max_score\n",
    "    # min_score = min(chunk for chunk in group)#group.min_score\n",
    "    currentDocumentChunksWithDistance = []\n",
    "    for _documentChunk in group:\n",
    "        score = _documentChunk.metadata.score\n",
    "        cuurrentChunkWithScore = ChunkWithScore.model_validate({**_documentChunk.properties, \"score\": score})\n",
    "        currentDocumentChunksWithDistance.append(cuurrentChunkWithScore)\n",
    "    \n",
    "    documentProperties = _documentChunk.references['belongsToDocument'].objects[0].properties\n",
    "    \n",
    "    documentSearchResult = DocumentSearchResult(\n",
    "        document_id=documentProperties['document_id'],\n",
    "        local_path=documentProperties['local_path'],\n",
    "        original_public_path=documentProperties['original_public_path'],\n",
    "        media_name=documentProperties['media_name'],\n",
    "        min_score=min(chunk.score for chunk in currentDocumentChunksWithDistance),\n",
    "        max_score=max(chunk.score for chunk in currentDocumentChunksWithDistance),\n",
    "        chunks=currentDocumentChunksWithDistance\n",
    "    )\n",
    "    documentsSearchResponse.append(documentSearchResult)\n",
    "for doc in documentsSearchResponse:\n",
    "    print(doc.media_name)\n",
    "    for chunk in doc.chunks:\n",
    "        print(f\"    -->  {chunk.score} | {chunk.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Document Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from weaviate.util import get_valid_uuid\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from collections import defaultdict\n",
    "from app.schemas import ChunkWithScore, DocumentSearchResult\n",
    "from weaviate.classes.query import Filter, GeoCoordinate, MetadataQuery, QueryReference, GroupBy\n",
    "\n",
    "\n",
    "query = \"l'île de Paques\"\n",
    "client = weaviate.connect_to_local()\n",
    "# print(\"SEARCH_MULTI_DOCUMENTS 0 \", query)\n",
    "document_chunk = client.collections.get(\"DocumentChunk\")\n",
    "response = document_chunk.query.hybrid(\n",
    "    query=query,\n",
    "    return_metadata=wvc.query.MetadataQuery(score=True),\n",
    "    query_properties=[\"text\"],\n",
    "    filters=Filter.by_ref(link_on=\"belongsToDocument\").by_property(\"document_id\").equal(get_valid_uuid(uuid=\"9e80a4c3-7139-4f66-b450-e94cbbf06e2b\")),\n",
    "    return_references=[QueryReference(link_on=\"belongsToDocument\", return_properties=[\"document_id\", \"local_path\", \"original_public_path\", \"media_name\", \"max_score\", \"min_score\"])]\n",
    ")\n",
    "# print(\"SEARCH_MULTI_DOCUMENTS 1 \", response)\n",
    "client.close()\n",
    "\n",
    "\n",
    "# Assume response is the result from the above query\n",
    "grouped_results = defaultdict(list)\n",
    "for chunk in response.objects:\n",
    "    doc_ref = chunk.references['belongsToDocument'].objects[0].properties\n",
    "    grouped_results[doc_ref['document_id']].append(chunk)\n",
    "\n",
    "# Now `grouped_results` contains your data grouped by 'document_id'\n",
    "# for document_id, chunks in grouped_results.items():\n",
    "#     print(f\"Media id: {document_id}, || Chunks: {chunks}\")\n",
    "\n",
    "documentsSearchResponse = []\n",
    "\n",
    "for document_id, group in grouped_results.items():  # View by group\n",
    "    # max_score = min(chunk for chunk in group)#group.max_score\n",
    "    # min_score = min(chunk for chunk in group)#group.min_score\n",
    "    currentDocumentChunksWithDistance = []\n",
    "    for _documentChunk in group:\n",
    "        score = _documentChunk.metadata.score\n",
    "        cuurrentChunkWithScore = ChunkWithScore.model_validate({**_documentChunk.properties, \"score\": score})\n",
    "        currentDocumentChunksWithDistance.append(cuurrentChunkWithScore)\n",
    "    \n",
    "    documentProperties = _documentChunk.references['belongsToDocument'].objects[0].properties\n",
    "    \n",
    "    documentSearchResult = DocumentSearchResult(\n",
    "        document_id=documentProperties['document_id'],\n",
    "        local_path=documentProperties['local_path'],\n",
    "        original_public_path=documentProperties['original_public_path'],\n",
    "        media_name=documentProperties['media_name'],\n",
    "        min_score=min(chunk.score for chunk in currentDocumentChunksWithDistance),\n",
    "        max_score=max(chunk.score for chunk in currentDocumentChunksWithDistance),\n",
    "        chunks=currentDocumentChunksWithDistance\n",
    "    )\n",
    "    documentsSearchResponse.append(documentSearchResult)\n",
    "for doc in documentsSearchResponse:\n",
    "    print(doc.media_name)\n",
    "    for chunk in doc.chunks:\n",
    "        print(f\"    -->  {chunk.score} | {chunk.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slack answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "DEBUGGGG --------------  Group(name='Ile de Paques : la théorie de l’effondrement précolonial à nouveau démentie | Actu de science', min_distance=-4.76837158203125e-07, max_distance=-4.76837158203125e-07, number_of_objects=1, objects=[GroupByObject(uuid=_WeaviateUUIDInt('1e1c4482-a564-4fc1-aa4c-52e51af53a87'), metadata=GroupByMetadataReturn(distance=-4.76837158203125e-07), properties={'local_path': '/home/erwan/Desktop/clients/ScienceInfuse/server/notebooks/../documents/youtube/9e80a4c3-7139-4f66-b450-e94cbbf06e2b.mp4', 'chunks': [{'end_offset': 18.0, 'media_type': 'youtube', 'start_offset': 2.0, 'text': \"Une croyance encore bien ancrée dans les esprits laisse penser que jadis, les habitants de l'île de Pâques, de son nom autochtone Rapanoui, auraient surexploité leur environnement naturel, provoquant ainsi eux-mêmes leur disparition. Mais cette hypothèse a été maintes fois démentie et une nouvelle étude enfonce le clou.\"}, {'start_offset': 25.0, 'end_offset': 158.0, 'text': \"En effet, l'île n'a jamais accueilli assez d'humains pour que cela ait entraîné leur Lorsque Rapa Nui est accosté par les colons européens, en 1722, il découvre d'imposantes statues de pierres érigées par milliers. Pourtant, il n'y a que 3 000 habitants sur place. Une question se pose alors, comment un si petit nombre d'individus a-t-il pu édifier de si nombreuses et si monumentales constructions ? Selon une idée popularisée par le géographe américain Jared Diamond il y a une vingtaine d'années, Rapa Nui était habité par de nombreux autochtones à même de dresser ces gigantesques statues. Mais en pliant les ressources naturelles dès avant l'arrivée des colons, ils auraient causé leur propre effondrement démographique. Or, les données scientifiques actuelles racontent une toute autre histoire. Une étude publiée en 2013 estimait que 4 à 21 km² de Rapa Nui étaient couverts de jardins de pierre utilisés pour cultiver des aliments comme des patates douces. L'île serait alors capable de nourrir jusqu'à 16 000 habitants. Mais ce chiffre est mis à mal par la dernière étude en date, publié le 21 juin dans Science Advances. En alliant imagerie satellite infrarouge à onde courte et intelligence artificielle, elle a pu identifier minutieusement les jardins de pierre en les distinguant des autres paysages rocheux de l'île, chose que l'étude de 2013 ne faisait pas de manière précise. Conclusion, les estimations de la quantité de jardins de pierre, ici en bleu, varient considérablement. À gauche, les estimations de l'étude de 2013, et à droite, celles de la récente étude. D'après cette dernière, les jardins de pierre ne couvraient en fait que 0,76 km² de l'île. Or, qui dit moins de jardins de pierre, dit moins d'aliments terrestres et donc moins d'habitants. L'île n'aurait en fait été capable d'accueillir que près de 4 000 habitants et non pas des dizaines de milliers. Pour l'archéologue Karl Lipo, qui a mené ses travaux, le récit d'un effondrement pré-européen n'a tout simplement aucun fondement. ni dans les archives archéologiques, ni dans la nature géologique du paysage, ni dans les ressources disponibles, ni dans les récits historiques. Si effondrement démographique il y a eu, c'est bien avec l'arrivée des colons européens qu'il s'est produit. Ce qu'on peut retenir de l'histoire des Rapanouis, en revanche, c'est l'ingéniosité avec laquelle ils ont exploité les maigres ressources disponibles sur leur île.\", 'media_type': 'youtube'}], 'media_name': 'Ile de Paques : la théorie de l’effondrement précolonial à nouveau démentie | Actu de science', 'original_public_path': 'https://www.youtube.com/watch?v=QMJmmJqDL1w', 'document_id': '9e80a4c3-7139-4f66-b450-e94cbbf06e2b'}, references={'hasChunks': <weaviate.collections.classes.internal._CrossReference object at 0x774c381aaf70>}, vector={}, collection='Document', belongs_to_group='Ile de Paques : la théorie de l’effondrement précolonial à nouveau démentie | Actu de science')], rerank_score=0.0)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for DocumentSearchResult\nchunks.0.score\n  Field required [type=missing, input_value={'media_type': 'youtube',....\", 'start_offset': 9.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nchunks.1.score\n  Field required [type=missing, input_value={'text': \"Les IRM du cerv...e', 'end_offset': 146.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# print(\"DEBUGGGG -------------- \", max_distance)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# print(\"DEBUGGGG -------------- \", min_distance)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# print(\"DEBUGGGG -------------- \", group)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m properties \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mobjects[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mproperties\n\u001b[0;32m---> 42\u001b[0m \u001b[43mDocumentSearchResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"chunks\": ChunkWithScore\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/scienceinfuse/lib/python3.9/site-packages/pydantic/main.py:551\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    550\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for DocumentSearchResult\nchunks.0.score\n  Field required [type=missing, input_value={'media_type': 'youtube',....\", 'start_offset': 9.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nchunks.1.score\n  Field required [type=missing, input_value={'text': \"Les IRM du cerv...e', 'end_offset': 146.0}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import weaviate.classes as wvc\n",
    "import weaviate\n",
    "from collections import defaultdict\n",
    "from app.schemas import ChunkWithScore, DocumentSearchResult\n",
    "from weaviate.classes.query import Filter, GeoCoordinate, MetadataQuery, QueryReference, GroupBy\n",
    "from weaviate.classes.query import QueryReference, Filter, GroupBy\n",
    "\n",
    "query = \"l'île de Pâques\"\n",
    "client = weaviate.connect_to_local()\n",
    "document_collection = client.collections.get(\"Document\")\n",
    "response = document_collection.query.hybrid(\n",
    "    query=\"document\",\n",
    "    group_by=GroupBy(prop=\"media_name\", objects_per_group=100, number_of_groups=100),\n",
    "    #filters=Filter.by_property(\"document_id\").equal(\"Document1\"),\n",
    "    return_metadata=wvc.query.MetadataQuery(score=True, distance=True, certainty=True),\n",
    "    return_references=QueryReference(\n",
    "        link_on=\"hasChunks\",\n",
    "        return_properties=[\"text\"],\n",
    "        return_metadata=wvc.query.MetadataQuery(score=True, distance=True, certainty=True),\n",
    "    ),\n",
    ")\n",
    "client.close()\n",
    "\n",
    "print(len(response.groups))\n",
    "\n",
    "for document_id, group in response.groups.items():  # View by group\n",
    "    max_distance = group.max_distance\n",
    "    min_distance = group.min_distance\n",
    "    currentDocumentChunksWithDistance = []\n",
    "    # print(f\"Group {document_id} has {len(group.objects)} objects\")\n",
    "    print(\"DEBUGGGG -------------- \", group)\n",
    "    # print(\"DEBUGGGG -------------- \", max_distance)\n",
    "    # print(\"DEBUGGGG -------------- \", min_distance)\n",
    "    # print(\"DEBUGGGG -------------- \", group)\n",
    "    \n",
    "    properties = group.objects[0].properties\n",
    "    DocumentSearchResult.model_validate({\n",
    "        **object.properties,\n",
    "        # \"chunks\": ChunkWithScore\n",
    "        \"max_score\": max_distance,\n",
    "        \"min_score\": min_distance,\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupByObject(uuid=_WeaviateUUIDInt('1e1c4482-a564-4fc1-aa4c-52e51af53a87'), metadata=GroupByMetadataReturn(distance=-4.76837158203125e-07), properties={'local_path': '/home/erwan/Desktop/clients/ScienceInfuse/server/notebooks/../documents/youtube/9e80a4c3-7139-4f66-b450-e94cbbf06e2b.mp4', 'chunks': [{'end_offset': 18.0, 'media_type': 'youtube', 'start_offset': 2.0, 'text': \"Une croyance encore bien ancrée dans les esprits laisse penser que jadis, les habitants de l'île de Pâques, de son nom autochtone Rapanoui, auraient surexploité leur environnement naturel, provoquant ainsi eux-mêmes leur disparition. Mais cette hypothèse a été maintes fois démentie et une nouvelle étude enfonce le clou.\"}, {'start_offset': 25.0, 'end_offset': 158.0, 'text': \"En effet, l'île n'a jamais accueilli assez d'humains pour que cela ait entraîné leur Lorsque Rapa Nui est accosté par les colons européens, en 1722, il découvre d'imposantes statues de pierres érigées par milliers. Pourtant, il n'y a que 3 000 habitants sur place. Une question se pose alors, comment un si petit nombre d'individus a-t-il pu édifier de si nombreuses et si monumentales constructions ? Selon une idée popularisée par le géographe américain Jared Diamond il y a une vingtaine d'années, Rapa Nui était habité par de nombreux autochtones à même de dresser ces gigantesques statues. Mais en pliant les ressources naturelles dès avant l'arrivée des colons, ils auraient causé leur propre effondrement démographique. Or, les données scientifiques actuelles racontent une toute autre histoire. Une étude publiée en 2013 estimait que 4 à 21 km² de Rapa Nui étaient couverts de jardins de pierre utilisés pour cultiver des aliments comme des patates douces. L'île serait alors capable de nourrir jusqu'à 16 000 habitants. Mais ce chiffre est mis à mal par la dernière étude en date, publié le 21 juin dans Science Advances. En alliant imagerie satellite infrarouge à onde courte et intelligence artificielle, elle a pu identifier minutieusement les jardins de pierre en les distinguant des autres paysages rocheux de l'île, chose que l'étude de 2013 ne faisait pas de manière précise. Conclusion, les estimations de la quantité de jardins de pierre, ici en bleu, varient considérablement. À gauche, les estimations de l'étude de 2013, et à droite, celles de la récente étude. D'après cette dernière, les jardins de pierre ne couvraient en fait que 0,76 km² de l'île. Or, qui dit moins de jardins de pierre, dit moins d'aliments terrestres et donc moins d'habitants. L'île n'aurait en fait été capable d'accueillir que près de 4 000 habitants et non pas des dizaines de milliers. Pour l'archéologue Karl Lipo, qui a mené ses travaux, le récit d'un effondrement pré-européen n'a tout simplement aucun fondement. ni dans les archives archéologiques, ni dans la nature géologique du paysage, ni dans les ressources disponibles, ni dans les récits historiques. Si effondrement démographique il y a eu, c'est bien avec l'arrivée des colons européens qu'il s'est produit. Ce qu'on peut retenir de l'histoire des Rapanouis, en revanche, c'est l'ingéniosité avec laquelle ils ont exploité les maigres ressources disponibles sur leur île.\", 'media_type': 'youtube'}], 'media_name': 'Ile de Paques : la théorie de l’effondrement précolonial à nouveau démentie | Actu de science', 'original_public_path': 'https://www.youtube.com/watch?v=QMJmmJqDL1w', 'document_id': '9e80a4c3-7139-4f66-b450-e94cbbf06e2b'}, references={'hasChunks': <weaviate.collections.classes.internal._CrossReference object at 0x774c381aaf70>}, vector={}, collection='Document', belongs_to_group='Ile de Paques : la théorie de l’effondrement précolonial à nouveau démentie | Actu de science')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group.objects[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scienceinfuse)",
   "language": "python",
   "name": "scienceinfuse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
